# CarRacing-v3 â€” DDQN Agent ğŸš—ğŸ’¨
A Reinforcement Learning project using a Double Deep Q-Network (DDQN) to learn how to drive in the Gymnasium CarRacing-v3 environment.  
The agent uses a convolutional neural network, frame-stacking, replay buffer, target network, epsilon decay, and reward shaping.

Work in progress â€” improving stability, adding visualizations, and refining hyperparameters.

---
<p float="left">
  <img src="./screenshots/first.gif" width="49%" />
  <img src="./screenshots/last.gif" width="49%" />
</p>

<p align="center">
  <b>Left:</b> Early training (episode 1) â€¢ 
  <b>Right:</b> Final agent behavior
</p>

---

## Features
- ğŸ® Trains on `CarRacing-v3` (Gymnasium)
- ğŸ§  DDQN architecture  
  - online network  
  - target network  
- ğŸ–¼ï¸ Preprocessing pipeline  
  - grayscale  
  - resize  
  - frame stacking  
- ğŸ—„ï¸ Replay buffer with random sampling
- ğŸ“‰ Epsilon-greedy exploration with decay
- ğŸ Reward shaping: off-road penalties, progress bonuses
- ğŸ“Š Training metrics (loss, reward, epsilon)
- ğŸ§ª Evaluation mode (no exploration)

---

## Tech Stack
- Python  
- PyTorch  
- Gymnasium  
- NumPy  
- Matplotlib  
- tqdm  

---

## Project Structure

```text
CarRacing-DDQN/
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ ddqn_cnn.py
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ replay_buffer.py
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ wrappers.py
â”‚   â””â”€â”€ plot.py
â”‚
â”œâ”€â”€ train.py
â”œâ”€â”€ evaluate.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## Training
Run:

```bash
python train.py
```

Optional flags:

```bash
python train.py --episodes 2000 --render False --save-interval 50
```

---

## Evaluation

```bash
python evaluate.py --model checkpoints/ddqn_500.pth
```

---

## Environment Variables (optional)

```env
SAVE_PATH=./checkpoints
DEVICE=cuda
```

---

## Screenshots

### Training reward curve
![Reward Curve](./screenshots/results.png)


---

## Future Improvements
- Prioritized experience replay  
- Dueling DDQN  
- Noisy layers  
- Soft updates for target network  
- Automated video logging  
- Better reward shaping  
- Hyperparameter sweeps  

---

## Work in Progress ğŸš§
Results and videos updated as training improves.
